{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Так, я хз работает или нет. Colab у меня закончился, а у компа 32гб ОЗУ не хватает, прошу больше такое не давать никому."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T13:03:18.561206Z",
     "start_time": "2025-06-13T13:03:18.558306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import help_l.tiny_img_dataset\n",
    "from help_l.tiny_img import download_tinyImg200"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T13:04:47.941991Z",
     "start_time": "2025-06-13T13:03:36.882740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = '.'\n",
    "download_tinyImg200(data_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset was downloaded to '.\\tiny-imagenet-200.zip'\n",
      "Extract downloaded dataset to '.'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T13:05:13.529012Z",
     "start_time": "2025-06-13T13:05:13.460474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_computing_device():\n",
    "    \"\"\"Return CUDA device if available else CPU\"\"\"\n",
    "    return torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "device = get_computing_device()\n",
    "print(f\"Our main computing device is '{device}'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our main computing device is 'cuda:0'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rS_-00tYDMoB",
    "ExecuteTime": {
     "end_time": "2025-06-13T13:05:14.853927Z",
     "start_time": "2025-06-13T13:05:14.850101Z"
    }
   },
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(5),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T13:24:11.494680Z",
     "start_time": "2025-06-13T13:17:09.116365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = help_l.tiny_img_dataset.TinyImagenetRAM(\n",
    "    'tiny-imagenet-200/train', transform=train_transforms\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tiny-imagenet-200/train: 100%|██████████| 200/200 [07:02<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T13:26:44.779022Z",
     "start_time": "2025-06-13T13:26:44.767939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TinyImagenetValDataset(Dataset):\n",
    "    \"\"\"Validation dataset that mimics TinyImagenetRAM API\"\"\"\n",
    "\n",
    "    def __init__(self, root: str, transform=transforms.ToTensor()):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        # Parse annotations\n",
    "        with open(os.path.join(root, 'val_annotations.txt')) as f:\n",
    "            annotations = [tuple(line.split('\\t')[:2]) for line in f]\n",
    "\n",
    "        # 1. Classes and mapping\n",
    "        self.classes = sorted({label for _, label in annotations})\n",
    "        assert len(self.classes) == 200, 'Unexpected number of classes'\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        # 2. Load images to RAM (same as TinyImagenetRAM)\n",
    "        self.images, self.targets = [], []\n",
    "        for img_name, class_name in tqdm.tqdm(annotations, desc='Loading val images'):\n",
    "            img_path = os.path.join(root, 'images', img_name)\n",
    "            image = help_l.tiny_img_dataset.read_rgb_image(img_path)\n",
    "            assert image.shape == (64, 64, 3), 'Image shape mismatch'\n",
    "            self.images.append(Image.fromarray(image))  # store as PIL for transforms\n",
    "            self.targets.append(self.class_to_idx[class_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.transform(self.images[idx])\n",
    "        target = self.targets[idx]\n",
    "        return img, target"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T13:29:16.127050Z",
     "start_time": "2025-06-13T13:26:46.698498Z"
    }
   },
   "cell_type": "code",
   "source": "val_dataset = TinyImagenetValDataset('tiny-imagenet-200/val', transform=transforms.ToTensor())",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val images: 100%|██████████| 10000/10000 [02:29<00:00, 66.94it/s] \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nV1W_7lix98w",
    "ExecuteTime": {
     "end_time": "2025-06-13T13:29:24.210473Z",
     "start_time": "2025-06-13T13:29:24.200408Z"
    }
   },
   "source": [
    "# Consistency checks\n",
    "assert train_dataset.classes == val_dataset.classes, 'Class order mismatch'\n",
    "assert train_dataset.class_to_idx == val_dataset.class_to_idx, 'Class‑index mapping differs'"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1749813848708,
     "user": {
      "displayName": "Даниил Пелагеев",
      "userId": "14704537345108617060"
     },
     "user_tz": -600
    },
    "id": "SNJFMLAFyHP0",
    "outputId": "4c2d0a79-9724-4664-ee3a-432ed0c3db0d",
    "ExecuteTime": {
     "end_time": "2025-06-13T13:29:25.703210Z",
     "start_time": "2025-06-13T13:29:25.680752Z"
    }
   },
   "source": [
    "batch_size = 64\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=12)\n",
    "\n",
    "val_batch_gen = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=12)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nkI9Wro8yMK7",
    "ExecuteTime": {
     "end_time": "2025-06-13T13:29:27.152827Z",
     "start_time": "2025-06-13T13:29:27.145949Z"
    }
   },
   "source": [
    "class GlobalAveragePool(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.mean(x, dim=self.dim)\n",
    "\n",
    "\n",
    "class ConvBNRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding='same'):\n",
    "        super().__init__()\n",
    "        pad = kernel_size // 2 if padding == 'same' else padding\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oeVX4j9MyP4K",
    "ExecuteTime": {
     "end_time": "2025-06-13T13:29:28.748348Z",
     "start_time": "2025-06-13T13:29:28.742280Z"
    }
   },
   "source": [
    "def create_vgg_like_network(config=None):\n",
    "    default_config = [[16, 16], [32, 32], [64, 64], [128, 128]]\n",
    "    config = config or default_config\n",
    "\n",
    "    model = nn.Sequential()\n",
    "    in_ch = 3\n",
    "    for block_i, block in enumerate(config):\n",
    "        for layer_i, out_ch in enumerate(block):\n",
    "            model.add_module(\n",
    "                f'conv_{block_i}_{layer_i}',\n",
    "                ConvBNRelu(in_ch, out_ch, kernel_size=3, stride=1, padding='same'),\n",
    "            )\n",
    "            in_ch = out_ch\n",
    "        if block_i != len(config) - 1:\n",
    "            model.add_module(f'mp_{block_i}', nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "\n",
    "    model.add_module('gap', GlobalAveragePool((2, 3)))\n",
    "    model.add_module('logits', nn.Linear(in_ch, 200))\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RVVt7MGayR1b",
    "ExecuteTime": {
     "end_time": "2025-06-13T13:29:30.136112Z",
     "start_time": "2025-06-13T13:29:30.128961Z"
    }
   },
   "source": [
    "class ResNetBlock2(nn.Module):\n",
    "    \"\"\"Simple 2‑layer residual block\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
    "        super().__init__()\n",
    "        pad = kernel_size // 2 if padding == 'same' else padding\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, 1, pad, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = None\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        out = self.relu2(out + identity)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GleycQzWyTuy",
    "ExecuteTime": {
     "end_time": "2025-06-13T13:29:32.365393Z",
     "start_time": "2025-06-13T13:29:32.355776Z"
    }
   },
   "source": [
    "def create_resnet_like_network():\n",
    "    model = nn.Sequential()\n",
    "    config = [[32, 32], [64, 64], [128, 128]]\n",
    "    model.add_module('init', ConvBNRelu(3, 32, kernel_size=7, stride=2, padding=3))\n",
    "\n",
    "    in_ch = 32\n",
    "    for block_i, block in enumerate(config):\n",
    "        for layer_i, out_ch in enumerate(block):\n",
    "            stride = 2 if block_i != 0 and layer_i == 0 else 1\n",
    "            model.add_module(\n",
    "                f'res_{block_i}_{layer_i}',\n",
    "                ResNetBlock2(in_ch, out_ch, kernel_size=3, stride=stride, padding='same'),\n",
    "            )\n",
    "            in_ch = out_ch\n",
    "    model.add_module('gap', GlobalAveragePool((2, 3)))\n",
    "    model.add_module('logits', nn.Linear(in_ch, 200))\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_loss(predictions, targets):\n",
    "    return F.cross_entropy(predictions, targets).mean()\n",
    "\n",
    "\n",
    "def eval_model(model, loader):\n",
    "    model.eval()\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            preds = logits.argmax(1)\n",
    "            acc.append((preds == y).float().mean().item())\n",
    "    return np.mean(acc)\n",
    "\n",
    "def train_model(model, optimizer, loader):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for X, y in tqdm.tqdm(loader, leave=False):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = compute_loss(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def train_loop(model, optimizer, train_loader, val_loader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        train_loss = train_model(model, optimizer, train_loader)\n",
    "        val_acc = eval_model(model, val_loader)\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{num_epochs} | time: {time.time() - start:.1f}s | \"\n",
    "            f\"train loss: {train_loss:.4f} | val acc: {val_acc * 100:.2f}%\"\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2z55F59Ayeb8",
    "outputId": "a9355905-a545-41b8-f9fd-bffea4db90bd",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-13T13:29:34.735414Z"
    }
   },
   "source": [
    "vgg_model = create_vgg_like_network().to(device)\n",
    "vgg_opt = torch.optim.Adam(vgg_model.parameters())\n",
    "train_loop(vgg_model, vgg_opt, train_batch_gen, val_batch_gen, num_epochs=30)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1563 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpLqUf-xygG9"
   },
   "outputs": [],
   "source": [
    "resnet_model = create_resnet_like_network().to(device)\n",
    "resnet_opt = torch.optim.Adam(resnet_model.parameters())\n",
    "train_loop(resnet_model, resnet_opt, train_batch_gen, val_batch_gen, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKQjy8S0yhpq"
   },
   "outputs": [],
   "source": [
    "larger_cfg = [[16, 16], [32, 32, 32, 32], [64, 64, 64, 64], [128, 128, 128, 128]]\n",
    "large_vgg_model = create_vgg_like_network(config=larger_cfg).to(device)\n",
    "large_vgg_opt = torch.optim.Adam(large_vgg_model.parameters())\n",
    "train_loop(large_vgg_model, large_vgg_opt, train_batch_gen, val_batch_gen, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "notebookId": "0bd81ca7-4175-4905-a84c-21ed8da72299"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
